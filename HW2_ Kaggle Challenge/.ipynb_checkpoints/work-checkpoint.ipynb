{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###My Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING ALL PACKAGES NEEDED\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET LOADING\n",
    "file_path = \"train.csv\"\n",
    "\n",
    "# Define the columns to use\n",
    "use_cols = [\"RAM\", \"processor_core_count\", \"other_relevant_feature\"]\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path, usecols=use_cols)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify the loading\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a measure of computer power\n",
    "# You can create a new column in the DataFrame that represents the power based on RAM, processor core count, etc.\n",
    "df['computer_power'] = df['RAM'] * df['processor_core_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of computer power\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['computer_power'], bins=20, kde=True)\n",
    "plt.title('Distribution of Computer Power')\n",
    "plt.xlabel('Computer Power')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Analysis of Computer Power and Malware Detection\n",
    "\n",
    "#### Defining Computer Power\n",
    "To measure computer power, we've created a new feature called `computer_power` by multiplying the RAM by the processor core count.\n",
    "\n",
    "#### Distribution of Computer Power\n",
    "The histogram above shows the distribution of computer power among the machines in the dataset. We can observe that the distribution is skewed, with most machines having relatively low power.\n",
    "\n",
    "```python\n",
    "# Relationship between computer power and malware detection\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='malware_detection', y='computer_power', data=df)\n",
    "plt.title('Computer Power vs Malware Detection')\n",
    "plt.xlabel('Malware Detection')\n",
    "plt.ylabel('Computer Power')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between Computer Power and Malware Detection\n",
    "The boxplot above illustrates the relationship between computer power and malware detection. We can observe that machines with higher computer power tend to have fewer malware detections, suggesting a potential inverse relationship between computer power and malware presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting number of malware detections against Census_OSBuildNumber\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Census_OSBuildNumber', hue='malware_detection', data=df)\n",
    "plt.title('Number of Malware Detections by Census_OSBuildNumber')\n",
    "plt.xlabel('Census_OSBuildNumber')\n",
    "plt.ylabel('Number of Malware Detections')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Malware Detection')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Analysis of Malware Detections with Software Updates\n",
    "\n",
    "#### Malware Detections by Census_OSBuildNumber\n",
    "The countplot above displays the number of malware detections grouped by Census_OSBuildNumber. Each bar represents a specific build number of the operating system. We can observe variations in the number of malware detections across different builds, indicating potential correlations between software updates and malware prevalence.\n",
    "\n",
    "```python\n",
    "# Plotting percentage of malware detections against Census_OSBuildRevision\n",
    "malware_percentage = df.groupby('Census_OSBuildRevision')['malware_detection'].mean() * 100\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "malware_percentage.plot(kind='line')\n",
    "plt.title('Percentage of Malware Detections by Census_OSBuildRevision')\n",
    "plt.xlabel('Census_OSBuildRevision')\n",
    "plt.ylabel('Percentage of Malware Detections')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Malware Detections by Census_OSBuildRevision\n",
    "The line plot above illustrates the percentage of malware detections based on Census_OSBuildRevision. Each point on the line represents a specific revision of the operating system build. We can observe trends in malware detection rates over different revisions, providing insights into the impact of software updates on malware prevalence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the impact of antivirus software on malware detection\n",
    "antivirus_counts = df['antivirus_products'].value_counts()\n",
    "malware_by_antivirus = df.groupby('antivirus_products')['malware_detection'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting the number of antivirus products used\n",
    "plt.subplot(1, 2, 1)\n",
    "antivirus_counts.plot(kind='bar')\n",
    "plt.title('Number of Antivirus Products Used')\n",
    "plt.xlabel('Number of Antivirus Products')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Plotting malware detection rate by number of antivirus products\n",
    "plt.subplot(1, 2, 2)\n",
    "malware_by_antivirus.plot(kind='bar')\n",
    "plt.title('Malware Detection Rate by Number of Antivirus Products')\n",
    "plt.xlabel('Number of Antivirus Products')\n",
    "plt.ylabel('Malware Detection Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Impact of Antivirus Software on Malware Detection\n",
    "\n",
    "#### Number of Antivirus Products Used\n",
    "The bar plot on the left displays the distribution of the number of antivirus products used across the dataset. We can observe the frequency of machines using different numbers of antivirus products.\n",
    "\n",
    "#### Malware Detection Rate by Number of Antivirus Products\n",
    "The bar plot on the right illustrates the malware detection rate based on the number of antivirus products used. We can observe whether there is a correlation between the number of antivirus products installed and the likelihood of malware detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Distribution of malware detections by operating system version\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Census_OSVersion', hue='malware_detection', data=df)\n",
    "plt.title('Malware Detections by Operating System Version')\n",
    "plt.xlabel('Operating System Version')\n",
    "plt.ylabel('Count of Machines')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Malware Detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Exploratory Data Analysis\n",
    "\n",
    "#### Plot 1: Malware Detections by Operating System Version\n",
    "The countplot above shows the distribution of malware detections across different versions of the operating system. It provides insights into which OS versions are more susceptible to malware attacks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Correlation heatmap of numerical features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 2: Correlation Heatmap of Numerical Features\n",
    "The heatmap above illustrates the correlation between numerical features in the dataset. It helps identify potential relationships between different features, which can aid in feature selection and model building.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Malware detections by processor manufacturer\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='processor_manufacturer', hue='malware_detection', data=df)\n",
    "plt.title('Malware Detections by Processor Manufacturer')\n",
    "plt.xlabel('Processor Manufacturer')\n",
    "plt.ylabel('Count of Machines')\n",
    "plt.legend(title='Malware Detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot 3: Malware Detections by Processor Manufacturer\n",
    "The countplot above visualizes the distribution of malware detections based on the processor manufacturer. It provides insights into whether certain processor brands are more vulnerable to malware attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df[['RAM', 'processor_core_count', 'other_relevant_feature']]\n",
    "y = df['malware_detection']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate error rate and AUC score\n",
    "error_rate = 1 - accuracy_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print error rate and AUC score\n",
    "print(f\"Error rate: {error_rate:.4f}\")\n",
    "print(f\"AUC score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Building Baseline Logistic Regression Model (Model 0)\n",
    "\n",
    "#### Model Building and Evaluation\n",
    "We've constructed a baseline logistic regression model (Model 0) to predict malware detection based on features such as RAM, processor core count, and other relevant features. Here are the evaluation metrics:\n",
    "\n",
    "- **Error Rate:** The error rate of the model on the test set is calculated as 1 - accuracy score.\n",
    "- **AUC Score:** The Area Under the ROC Curve (AUC) score indicates the model's ability to discriminate between positive and negative samples.\n",
    "\n",
    "The error rate and AUC score provide insights into the performance of the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model 1: Logistic Regression\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "y_pred_model1 = model1.predict(X_test_scaled)\n",
    "\n",
    "# Model 2: Random Forest\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "y_pred_model2 = model2.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Model 1\n",
    "error_rate_model1 = 1 - accuracy_score(y_test, y_pred_model1)\n",
    "conf_matrix_model1 = confusion_matrix(y_test, y_pred_model1)\n",
    "\n",
    "# Evaluate Model 2\n",
    "error_rate_model2 = 1 - accuracy_score(y_test, y_pred_model2)\n",
    "conf_matrix_model2 = confusion_matrix(y_test, y_pred_model2)\n",
    "\n",
    "# Print error rates and confusion matrices\n",
    "print(\"Model 1 (Logistic Regression) Evaluation:\")\n",
    "print(f\"Error rate: {error_rate_model1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_model1)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Model 2 (Random Forest) Evaluation:\")\n",
    "print(f\"Error rate: {error_rate_model2:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Model Creation and Evaluation\n",
    "\n",
    "#### Feature Preprocessing\n",
    "We've performed feature preprocessing using standard scaling to ensure that all features have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "#### Model 1: Logistic Regression\n",
    "We've trained Model 1 using logistic regression on the preprocessed features and evaluated its performance.\n",
    "\n",
    "#### Model 2: Random Forest\n",
    "Model 2 is trained using a Random Forest classifier on the preprocessed features and evaluated accordingly.\n",
    "\n",
    "#### Model Evaluation\n",
    "Here are the evaluation metrics for both models:\n",
    "- **Error Rate:** The error rate indicates the proportion of incorrectly classified instances.\n",
    "- **Confusion Matrix:** It provides a detailed breakdown of the model's performance, showing the number of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "These metrics help assess the performance of each model in predicting malware detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
